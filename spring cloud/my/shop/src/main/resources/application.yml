eureka:
  client:
    service-url:
      defaultZone: http://localhost:9001/eureka/
  instance:
    instance-id:  shops #显示此名字(默认是当前项目http://localhost:8001)
    prefer-ip-address: true #访问路径可以显示ip地址
server:
  port: 9004
logging:
  config: classpath:log4j2.yml
spring:
  application:
    name: server-shop
  datasource:
    driver-class-name: com.mysql.cj.jdbc.Driver
    url: jdbc:mysql://49.235.54.66:3306/my?serverTimezone=GMT%2B8&useUnicode=true&characterEncoding=utf-8
    username: root
    password: 6301664
    platform: mysql
    type: com.alibaba.druid.pool.DruidDataSource
    initialSize: 1
    minIdle: 3
    maxActive: 20
    # 配置获取连接等待超时的时间
    maxWait: 60000
    # 配置间隔多久才进行一次检测，检测需要关闭的空闲连接，单位是毫秒
    timeBetweenEvictionRunsMillis: 60000
    # 配置一个连接在池中最小生存的时间，单位是毫秒
    minEvictableIdleTimeMillis: 30000
    validationQuery: select 'x'
    testWhileIdle: true
    testOnBorrow: false
    testOnReturn: false
    # 打开PSCache，并且指定每个连接上PSCache的大小
    poolPreparedStatements: true
    maxPoolPreparedStatementPerConnectionSize: 20
    # 配置监控统计拦截的filters，去掉后监控界面sql无法统计，'wall'用于防火墙
    filters: stat,wall,log4j2
    # 通过connectProperties属性来打开mergeSql功能；慢SQL记录
    connectionProperties: druid.stat.mergeSql=true;druid.stat.slowSqlMillis=5000
    # 合并多个DruidDataSource的监控数据
    #useGlobalDataSourceStat: true
  jpa:
    show-sql: true
    hibernate:
      ddl-auto: none
    properties:
      hibernate:
        dialect: org.hibernate.dialect.MySQL5InnoDBDialect
  servlet:
    multipart:
      max-file-size: 20MB
      max-request-size: 20MB




##kafka相关配置
#  spring.kafka.bootstrap-servers=阿里云外网ip:9092
#  #设置一个默认组
#  spring.kafka.consumer.group-id=defaultGroup
#  #key-value序列化反序列化
#  spring.kafka.consumer.key-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#  spring.kafka.consumer.value-deserializer=org.apache.kafka.common.serialization.StringDeserializer
#  spring.kafka.producer.key-serializer=org.apache.kafka.common.serialization.StringSerializer
#  spring.kafka.producer.value-serializer=org.apache.kafka.common.serialization.StringSerializer
#  spring.kafka.producer.batch-size=65536
#  spring.kafka.producer.buffer-memory=524288